{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Build a CNN for image recognition.\n",
    "\n",
    "## Due Date:  March 29, 11:59PM\n",
    "\n",
    "### Name: [Your-Name?]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "1. In this assignment, you will build Convolutional Neural Network to classify CIFAR-10 Images.\n",
    "2. You can directly load dataset from many deep learning packages.\n",
    "3. You can use any deep learning packages such as pytorch, keras or tensorflow for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "\n",
    "1. You need to load cifar 10 data and split the entire training dataset into training and validation.\n",
    "2. You will implement a CNN model to classify cifar 10 images with provided structure.\n",
    "3. You need to plot the training and validation accuracy or loss obtained from above step.\n",
    "4. Then you can use tuned parameters to train using the entire training dataset.\n",
    "5. You should report the testing accuracy using the model with complete data.\n",
    "6. You may try to change the structure (e.g, add BN layer or dropout layer,...) and analyze your findings.\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization (BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Batch Normalization is a technique to speed up training and help make the model more stable.\n",
    "- In simple words, batch normalization is just another network layer that gets inserted between a hidden layer and the next hidden layer. Its job is to take the outputs from the first hidden layer and normalize them before passing them on as the input of the next hidden layer.\n",
    "\n",
    "- For more detailed information, you may refer to the original paper: https://arxiv.org/pdf/1502.03167.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: Values of $x$ over a mini-batch: $\\mathbf{B}$ = $\\{x_1,..., x_m\\};$\n",
    "- Output: $\\{y_i = BN_{\\gamma,\\beta}(x_i)\\}$, $\\gamma, \\beta$ are learnable parameters\n",
    "\n",
    "Normalization of the Input:\n",
    "$$\\mu_{\\mathbf{B}} = \\frac{1}{m}\\sum_{i=1}^m x_i$$\n",
    "$$\\sigma_{\\mathbf{B}}^2 = \\frac{1}{m}\\sum_{i=1}^m (x_i - \\mu_{\\mathbf{B}})^2$$\n",
    "$$\\hat{x_i} = \\frac{x_i - \\mu_{\\mathbf{B}}}{\\sqrt{\\sigma_{\\mathbf{B}}}^2 + \\epsilon}$$\n",
    "Re-scaling and Offsetting:\n",
    "$$y_i = \\gamma \\hat{x_i} + \\beta = BN_{\\gamma,\\beta}(x_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of BN:\n",
    "1. Improves gradient flow through the network.\n",
    "2. Allows use of saturating nonlinearities and higher learning rates.\n",
    "3. Makes weights easier to initialize.\n",
    "4. Act as a form of regularization and may reduce the need for dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The batch normalization layer has already been implemented in many packages. You may simply call the function to build the layer. For example: torch.nn.BatchNorm2d() using pytroch package, keras.layers.BatchNormalization() using keras package.\n",
    "- The location of BN layer: Please make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Load Cifar-10 Data\n",
    "# This is just an example, you may load dataset from other packages.\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "### If you can not load keras dataset, un-comment these two lines.\n",
    "#import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels (5 points)\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Implement a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "[9]\n",
      "[9]\n",
      "[4]\n",
      "[1]\n",
      "[1]\n",
      "[2]\n",
      "[7]\n",
      "[8]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    y_train_new = np.zeros((len(y),num_class))\n",
    "    for i in range(len(y)):\n",
    "        array1 = [0 for x in range(10)]\n",
    "        a = y[i]\n",
    "        array1[a[0]] =1\n",
    "        y_train_new[i] = array1\n",
    "    return y_train_new\n",
    "        \n",
    "        \n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets (5 points)\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets: \n",
    "* a training set containing 40K samples: x_tr, y_tr\n",
    "* a validation set containing 10K samples: x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    np.random.seed(42)\n",
    "    random_indices = np.random.permutation(len(data))\n",
    "    validation_set_size = int(len(data)*test_ratio)\n",
    "    validation_indices = random_indices[:validation_set_size]\n",
    "    train_indices = random_indices[validation_set_size:]\n",
    "    return data[train_indices],data[validation_indices]\n",
    "\n",
    "x_tr,x_val = split_train_test(x_train,0.2)\n",
    "y_tr,y_val = split_train_test(y_train_vec,0.2)\n",
    "\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters (50 points)\n",
    "\n",
    "- Build a convolutional neural network model using the below structure:\n",
    "\n",
    "- It should have a structure of: Conv - ReLU - Max Pool - ConV - ReLU - Max Pool - Dense - ReLU - Dense - Softmax\n",
    "\n",
    "- In the graph 3@32x32 means the dimension of input image, 32@30x30 means it has 32 filters and the dimension now becomes 30x30 after the convolution.\n",
    "- All convolutional layers (Conv) should have stride = 1 and no padding.\n",
    "- Max Pooling has a pool size of 2 by 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"network.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You may use the validation data to tune the hyper-parameters (e.g., learning rate, and optimization algorithm)\n",
    "- Do NOT use test data for hyper-parameter tuning!!!\n",
    "- Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 16:31:58.215438: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32,3, activation='relu',input_shape=[32,32,3]),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Conv2D(64,4,activation='relu'),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "from keras import optimizers\n",
    "model.compile(optimizers.rmsprop_v2.RMSprop(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               590080    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 626,378\n",
      "Trainable params: 626,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 4.2877 - accuracy: 0.2920 - val_loss: 1.8678 - val_accuracy: 0.3796\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 1.6018 - accuracy: 0.4478 - val_loss: 1.5319 - val_accuracy: 0.4736\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 1.3344 - accuracy: 0.5358 - val_loss: 1.4348 - val_accuracy: 0.5065\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 1.1656 - accuracy: 0.5980 - val_loss: 1.3670 - val_accuracy: 0.5305\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 1.0325 - accuracy: 0.6443 - val_loss: 1.4004 - val_accuracy: 0.5395\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.9189 - accuracy: 0.6886 - val_loss: 1.3551 - val_accuracy: 0.5533\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.8191 - accuracy: 0.7206 - val_loss: 1.3127 - val_accuracy: 0.5804\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.7327 - accuracy: 0.7512 - val_loss: 1.2691 - val_accuracy: 0.5895\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6508 - accuracy: 0.7831 - val_loss: 1.2470 - val_accuracy: 0.6013\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.5753 - accuracy: 0.8085 - val_loss: 1.3891 - val_accuracy: 0.5724\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.5084 - accuracy: 0.8326 - val_loss: 1.3390 - val_accuracy: 0.5993\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.4431 - accuracy: 0.8576 - val_loss: 1.3791 - val_accuracy: 0.5963\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.3895 - accuracy: 0.8758 - val_loss: 1.5135 - val_accuracy: 0.5810\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.3404 - accuracy: 0.8943 - val_loss: 1.4842 - val_accuracy: 0.5995\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.2925 - accuracy: 0.9115 - val_loss: 1.5177 - val_accuracy: 0.6021\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.2503 - accuracy: 0.9260 - val_loss: 1.5197 - val_accuracy: 0.6089\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.2147 - accuracy: 0.9394 - val_loss: 1.5453 - val_accuracy: 0.6143\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.1796 - accuracy: 0.9513 - val_loss: 1.6183 - val_accuracy: 0.6128\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.1508 - accuracy: 0.9602 - val_loss: 1.6987 - val_accuracy: 0.6040\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.1255 - accuracy: 0.9682 - val_loss: 1.7006 - val_accuracy: 0.6174\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.1028 - accuracy: 0.9768 - val_loss: 1.8453 - val_accuracy: 0.6088\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0847 - accuracy: 0.9802 - val_loss: 1.9378 - val_accuracy: 0.6044\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 0.0698 - accuracy: 0.9857 - val_loss: 1.9655 - val_accuracy: 0.6154\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0585 - accuracy: 0.9884 - val_loss: 2.0324 - val_accuracy: 0.6127\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0489 - accuracy: 0.9910 - val_loss: 2.1094 - val_accuracy: 0.6180\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0392 - accuracy: 0.9933 - val_loss: 2.1267 - val_accuracy: 0.6257\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0347 - accuracy: 0.9935 - val_loss: 2.1915 - val_accuracy: 0.6229\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0302 - accuracy: 0.9944 - val_loss: 2.2742 - val_accuracy: 0.6220\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0294 - accuracy: 0.9938 - val_loss: 2.3271 - val_accuracy: 0.6183\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0225 - accuracy: 0.9959 - val_loss: 2.4443 - val_accuracy: 0.6192\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0212 - accuracy: 0.9962 - val_loss: 2.5787 - val_accuracy: 0.6110\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 2.5241 - val_accuracy: 0.6129\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 2.5795 - val_accuracy: 0.6125\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 2.5287 - val_accuracy: 0.6275\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 2.6526 - val_accuracy: 0.6260\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 2.6321 - val_accuracy: 0.6289\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0116 - accuracy: 0.9975 - val_loss: 2.8375 - val_accuracy: 0.6163\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 2.8177 - val_accuracy: 0.6213\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 2.7520 - val_accuracy: 0.6326\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 2.7824 - val_accuracy: 0.6320\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 2.8317 - val_accuracy: 0.6278\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 2.8387 - val_accuracy: 0.6284\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 2.8803 - val_accuracy: 0.6266\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 2.9193 - val_accuracy: 0.6324\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 2.9135 - val_accuracy: 0.6287\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 3.0442 - val_accuracy: 0.6234\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 3.0778 - val_accuracy: 0.6266\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 3.0932 - val_accuracy: 0.6197\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 3.2270 - val_accuracy: 0.6222\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 3.2029 - val_accuracy: 0.6253\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "history = model.fit(x_tr,y_tr,\n",
    "                    batch_size=128, epochs =50,\n",
    "                   validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment_2_first_model_train_loss -> [4.287698268890381, 1.6017961502075195, 1.3344250917434692, 1.1655800342559814, 1.0324889421463013, 0.9188665151596069, 0.8191154599189758, 0.7327010631561279, 0.6507695317268372, 0.5752825140953064, 0.508366048336029, 0.44309863448143005, 0.3894880414009094, 0.3404024839401245, 0.2924562692642212, 0.2502696216106415, 0.21474798023700714, 0.17958031594753265, 0.15080691874027252, 0.12552130222320557, 0.10282555222511292, 0.08474047482013702, 0.06976619362831116, 0.058530714362859726, 0.04886357858777046, 0.03924575075507164, 0.034725483506917953, 0.030157381668686867, 0.029425092041492462, 0.02246495708823204, 0.021160384640097618, 0.018627822399139404, 0.01759880594909191, 0.01583228074014187, 0.015167506411671638, 0.012239744886755943, 0.011631271801888943, 0.011531160213053226, 0.009783292189240456, 0.010483259335160255, 0.010564981959760189, 0.008432175032794476, 0.009430747479200363, 0.009432001039385796, 0.010240097530186176, 0.008452351205050945, 0.00914792437106371, 0.0070702796801924706, 0.006315391510725021, 0.006913140881806612] 50\n",
      "Assignment_2_first_model_val_loss -> [1.8677623271942139, 1.5319461822509766, 1.434849500656128, 1.3669989109039307, 1.4004249572753906, 1.3551430702209473, 1.312660574913025, 1.2691192626953125, 1.2469762563705444, 1.3890959024429321, 1.3390178680419922, 1.379141092300415, 1.5135198831558228, 1.4842385053634644, 1.5176923274993896, 1.5196654796600342, 1.5453277826309204, 1.618308424949646, 1.698736548423767, 1.7006179094314575, 1.845263123512268, 1.9378408193588257, 1.9654574394226074, 2.0324041843414307, 2.1093647480010986, 2.1266562938690186, 2.191498041152954, 2.274172782897949, 2.3271024227142334, 2.4442553520202637, 2.5786828994750977, 2.5241057872772217, 2.579533100128174, 2.528681993484497, 2.6525917053222656, 2.632101058959961, 2.837493658065796, 2.8177216053009033, 2.7519872188568115, 2.7824437618255615, 2.8316709995269775, 2.8387041091918945, 2.880286693572998, 2.9192800521850586, 2.9134747982025146, 3.044177293777466, 3.077773332595825, 3.0931785106658936, 3.226989984512329, 3.2028517723083496] 50\n"
     ]
    }
   ],
   "source": [
    "model.save('Assignment_2_first_model.h5')\n",
    "Assignment_2_first_model_train_loss = history.history['loss']\n",
    "Assignment_2_first_model_val_loss = history.history['val_loss']\n",
    "print('Assignment_2_first_model_train_loss ->',Assignment_2_first_model_train_loss,len(Assignment_2_first_model_train_loss))\n",
    "print('Assignment_2_first_model_val_loss ->',Assignment_2_first_model_val_loss,len(Assignment_2_first_model_val_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the training and validation loss curve versus epochs. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = range(50)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(epochs,train_loss,'bo',label= 'Training Loss')\n",
    "plt.plot(epochs,val_loss,'r',label= 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train (again) and evaluate the model (5 points)\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
    "from keras import optimizers\n",
    "model.compile(optimizers.rmsprop_v2.RMSprop(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 5.8414 - accuracy: 0.2744\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 1.6306 - accuracy: 0.4472\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 1.3131 - accuracy: 0.5448\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 30s 78ms/step - loss: 1.1372 - accuracy: 0.6071\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 30s 78ms/step - loss: 1.0013 - accuracy: 0.6551\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 30s 76ms/step - loss: 0.8900 - accuracy: 0.6941\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 30s 78ms/step - loss: 0.7919 - accuracy: 0.7297\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 0.7069 - accuracy: 0.7593\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.6287 - accuracy: 0.7875\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.5556 - accuracy: 0.8131\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.4907 - accuracy: 0.8371\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.4300 - accuracy: 0.8603\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.3737 - accuracy: 0.8798\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 28s 70ms/step - loss: 0.3239 - accuracy: 0.8978\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 26s 68ms/step - loss: 0.2757 - accuracy: 0.9142\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.2351 - accuracy: 0.9298\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.1987 - accuracy: 0.9411\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.1668 - accuracy: 0.9529\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 26s 68ms/step - loss: 0.1379 - accuracy: 0.9631\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.1128 - accuracy: 0.9716\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.0942 - accuracy: 0.9769\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.0766 - accuracy: 0.9825\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.0630 - accuracy: 0.9866\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 26s 68ms/step - loss: 0.0525 - accuracy: 0.9890\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.0437 - accuracy: 0.9911\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.0367 - accuracy: 0.9926\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.0302 - accuracy: 0.9942\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.0265 - accuracy: 0.9948\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.0244 - accuracy: 0.9949\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.0203 - accuracy: 0.9959\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 0.0189 - accuracy: 0.9960\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 26s 68ms/step - loss: 0.0161 - accuracy: 0.9963\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 26s 65ms/step - loss: 0.0153 - accuracy: 0.9969\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.0154 - accuracy: 0.9965\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.0134 - accuracy: 0.9968\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.0128 - accuracy: 0.9970\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 25s 64ms/step - loss: 0.0141 - accuracy: 0.9965\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 26s 65ms/step - loss: 0.0111 - accuracy: 0.9976\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.0110 - accuracy: 0.9972\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.0109 - accuracy: 0.9971\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 26s 65ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.0096 - accuracy: 0.9973\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.0101 - accuracy: 0.9977\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.0095 - accuracy: 0.9978\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 0.0110 - accuracy: 0.9969\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.0090 - accuracy: 0.9976\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 25s 64ms/step - loss: 0.0079 - accuracy: 0.9980\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 25s 64ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 25s 64ms/step - loss: 0.0075 - accuracy: 0.9982\n"
     ]
    }
   ],
   "source": [
    "#<Train your model on the entire training set (50K samples)>\n",
    "history2 = model.fit(x_train,y_train_vec,\n",
    "                    batch_size=128, epochs =50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the model on the test set (5 points)\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 6ms/step - loss: 3.0351 - accuracy: 0.6519\n",
      "loss =  3.035090684890747\n",
      "accuracy =  0.6518999934196472\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "loss_and_acc = model.evaluate(x_test,y_test_vec)\n",
    "print('loss = ', str(loss_and_acc[0]))\n",
    "print('accuracy = ', str(loss_and_acc[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building model with new structure (25 points)\n",
    "- In this section, you can build your model with adding new layers (e.g, BN layer or dropout layer, ...).\n",
    "- If you want to regularize a ```Conv/Dense layer```, you should place a ```Dropout layer``` before the ```Conv/Dense layer```.\n",
    "- You can try to compare their loss curve and testing accuracy and analyze your findings.\n",
    "- You need to try at lease two different model structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               590080    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 626,378\n",
      "Trainable params: 626,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.9654 - accuracy: 0.6666 - val_loss: 215.4222 - val_accuracy: 0.0875\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.9604 - accuracy: 0.6637 - val_loss: 238.4451 - val_accuracy: 0.0850\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.9601 - accuracy: 0.6658 - val_loss: 216.2220 - val_accuracy: 0.1050\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.9491 - accuracy: 0.6650 - val_loss: 223.5060 - val_accuracy: 0.0925\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9420 - accuracy: 0.6726 - val_loss: 220.2229 - val_accuracy: 0.1275\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.9236 - accuracy: 0.6779 - val_loss: 238.8087 - val_accuracy: 0.1100\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.9257 - accuracy: 0.6785 - val_loss: 243.1367 - val_accuracy: 0.1350\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.9142 - accuracy: 0.6826 - val_loss: 250.5981 - val_accuracy: 0.0925\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.9168 - accuracy: 0.6815 - val_loss: 246.4700 - val_accuracy: 0.1275\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.9091 - accuracy: 0.6813 - val_loss: 254.3505 - val_accuracy: 0.0875\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.9011 - accuracy: 0.6846 - val_loss: 240.0384 - val_accuracy: 0.1025\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.8910 - accuracy: 0.6925 - val_loss: 264.1412 - val_accuracy: 0.0900\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.8893 - accuracy: 0.6928 - val_loss: 252.9097 - val_accuracy: 0.0975\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 27s 26ms/step - loss: 0.8942 - accuracy: 0.6908 - val_loss: 241.0367 - val_accuracy: 0.1200\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.8838 - accuracy: 0.6913 - val_loss: 254.1356 - val_accuracy: 0.1075\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.8801 - accuracy: 0.6922 - val_loss: 240.0927 - val_accuracy: 0.1025\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.8734 - accuracy: 0.6961 - val_loss: 232.6072 - val_accuracy: 0.1025\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.8782 - accuracy: 0.6943 - val_loss: 242.3454 - val_accuracy: 0.1225\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.8652 - accuracy: 0.7009 - val_loss: 245.8454 - val_accuracy: 0.1025\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.8604 - accuracy: 0.7015 - val_loss: 268.7341 - val_accuracy: 0.0800\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8604 - accuracy: 0.7013 - val_loss: 254.6558 - val_accuracy: 0.1025\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.8546 - accuracy: 0.7051 - val_loss: 275.5574 - val_accuracy: 0.0950\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.8509 - accuracy: 0.7030 - val_loss: 260.3649 - val_accuracy: 0.0875\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8454 - accuracy: 0.7078 - val_loss: 261.0072 - val_accuracy: 0.1125\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.8432 - accuracy: 0.7074 - val_loss: 267.9139 - val_accuracy: 0.1250\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.8449 - accuracy: 0.7075 - val_loss: 262.5393 - val_accuracy: 0.1100\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.8396 - accuracy: 0.7098 - val_loss: 268.1743 - val_accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.8316 - accuracy: 0.7136 - val_loss: 264.9681 - val_accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.8218 - accuracy: 0.7172 - val_loss: 261.8637 - val_accuracy: 0.1025\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.8295 - accuracy: 0.7134 - val_loss: 251.1314 - val_accuracy: 0.1125\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.8271 - accuracy: 0.7127 - val_loss: 282.1612 - val_accuracy: 0.0650\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.8245 - accuracy: 0.7133 - val_loss: 284.9640 - val_accuracy: 0.1475\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.8270 - accuracy: 0.7152 - val_loss: 266.3420 - val_accuracy: 0.0975\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.8231 - accuracy: 0.7140 - val_loss: 277.5393 - val_accuracy: 0.1125\n",
      "Epoch 35/100\n",
      " 822/1000 [=======================>......] - ETA: 4s - loss: 0.8241 - accuracy: 0.7164"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mb/fzndffws2vn5fyk_kfbd1ft00000gq/T/ipykernel_94978/855675256.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history_4 = model.fit(datagen.flow(x_train, y_train_vec, batch_size=32,\n\u001b[0m\u001b[1;32m      2\u001b[0m          subset='training'),\n\u001b[1;32m      3\u001b[0m          validation_data=datagen.flow(x_train, y_train,\n\u001b[1;32m      4\u001b[0m          batch_size=8, subset='validation'),\n\u001b[1;32m      5\u001b[0m          steps_per_epoch=1000, epochs=100,validation_steps=50)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_4 = model.fit(datagen.flow(x_train, y_train_vec, batch_size=32,\n",
    "         subset='training'),\n",
    "         validation_data=datagen.flow(x_train, y_train,\n",
    "         batch_size=8, subset='validation'),\n",
    "         steps_per_epoch=1000, epochs=100,validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model_2 = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32,3, activation='relu',input_shape=[32,32,3]),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Conv2D(64,4,activation='relu'),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizers.rmsprop_v2.RMSprop(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 22s 68ms/step - loss: 4.8816 - accuracy: 0.1761 - val_loss: 2.0141 - val_accuracy: 0.2594\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.9510 - accuracy: 0.2949 - val_loss: 1.7518 - val_accuracy: 0.3686\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 32s 103ms/step - loss: 1.7874 - accuracy: 0.3540 - val_loss: 1.6454 - val_accuracy: 0.3972\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 1.6994 - accuracy: 0.3863 - val_loss: 1.5444 - val_accuracy: 0.4477\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 1.6268 - accuracy: 0.4150 - val_loss: 1.5173 - val_accuracy: 0.4584\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 1.5733 - accuracy: 0.4332 - val_loss: 1.4781 - val_accuracy: 0.4653\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 1.5201 - accuracy: 0.4560 - val_loss: 1.4037 - val_accuracy: 0.4958\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.4769 - accuracy: 0.4727 - val_loss: 1.4082 - val_accuracy: 0.5011\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.4209 - accuracy: 0.4949 - val_loss: 1.3529 - val_accuracy: 0.5104\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 23s 72ms/step - loss: 1.3862 - accuracy: 0.5110 - val_loss: 1.2856 - val_accuracy: 0.5484\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 1.3555 - accuracy: 0.5202 - val_loss: 1.2798 - val_accuracy: 0.5475\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.3193 - accuracy: 0.5332 - val_loss: 1.2605 - val_accuracy: 0.5529\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.2830 - accuracy: 0.5476 - val_loss: 1.2108 - val_accuracy: 0.5735\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 1.2569 - accuracy: 0.5599 - val_loss: 1.2374 - val_accuracy: 0.5648\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 1.2243 - accuracy: 0.5708 - val_loss: 1.1804 - val_accuracy: 0.5936\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 1.1988 - accuracy: 0.5802 - val_loss: 1.2494 - val_accuracy: 0.5722\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.1669 - accuracy: 0.5900 - val_loss: 1.3222 - val_accuracy: 0.5501\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.1487 - accuracy: 0.5994 - val_loss: 1.1312 - val_accuracy: 0.6080\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 1.1222 - accuracy: 0.6070 - val_loss: 1.1046 - val_accuracy: 0.6140\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.1009 - accuracy: 0.6168 - val_loss: 1.1541 - val_accuracy: 0.5980\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.0813 - accuracy: 0.6217 - val_loss: 1.1161 - val_accuracy: 0.6126\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 1.0610 - accuracy: 0.6289 - val_loss: 1.1274 - val_accuracy: 0.6045\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.0401 - accuracy: 0.6385 - val_loss: 1.0537 - val_accuracy: 0.6440\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.0175 - accuracy: 0.6461 - val_loss: 1.0637 - val_accuracy: 0.6377\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 22s 72ms/step - loss: 1.0012 - accuracy: 0.6528 - val_loss: 1.0924 - val_accuracy: 0.6168\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.9785 - accuracy: 0.6596 - val_loss: 1.0534 - val_accuracy: 0.6393\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.9702 - accuracy: 0.6620 - val_loss: 1.1054 - val_accuracy: 0.6192\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.9525 - accuracy: 0.6701 - val_loss: 1.0683 - val_accuracy: 0.6412\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.9347 - accuracy: 0.6753 - val_loss: 1.0155 - val_accuracy: 0.6509\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.9142 - accuracy: 0.6851 - val_loss: 1.0174 - val_accuracy: 0.6522\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.9047 - accuracy: 0.6865 - val_loss: 1.0482 - val_accuracy: 0.6450\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 22s 72ms/step - loss: 0.8878 - accuracy: 0.6901 - val_loss: 0.9875 - val_accuracy: 0.6618\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8748 - accuracy: 0.6986 - val_loss: 1.0255 - val_accuracy: 0.6533\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.8630 - accuracy: 0.7016 - val_loss: 1.0000 - val_accuracy: 0.6635\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.8419 - accuracy: 0.7067 - val_loss: 0.9804 - val_accuracy: 0.6614\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8306 - accuracy: 0.7138 - val_loss: 0.9598 - val_accuracy: 0.6797\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.8141 - accuracy: 0.7188 - val_loss: 1.1475 - val_accuracy: 0.6182\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.8064 - accuracy: 0.7192 - val_loss: 0.9910 - val_accuracy: 0.6702\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.7951 - accuracy: 0.7230 - val_loss: 0.9728 - val_accuracy: 0.6797\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.7752 - accuracy: 0.7311 - val_loss: 0.9588 - val_accuracy: 0.6800\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.7643 - accuracy: 0.7358 - val_loss: 0.9927 - val_accuracy: 0.6655\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.7579 - accuracy: 0.7393 - val_loss: 0.9744 - val_accuracy: 0.6774\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.7474 - accuracy: 0.7404 - val_loss: 0.9765 - val_accuracy: 0.6770\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.7389 - accuracy: 0.7429 - val_loss: 0.9566 - val_accuracy: 0.6831\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.7223 - accuracy: 0.7499 - val_loss: 0.9768 - val_accuracy: 0.6755\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.7070 - accuracy: 0.7519 - val_loss: 0.9733 - val_accuracy: 0.6786\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7035 - accuracy: 0.7542 - val_loss: 0.9448 - val_accuracy: 0.6857\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.6869 - accuracy: 0.7608 - val_loss: 0.9286 - val_accuracy: 0.6906\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.6743 - accuracy: 0.7648 - val_loss: 0.9288 - val_accuracy: 0.6902\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.6721 - accuracy: 0.7671 - val_loss: 0.9530 - val_accuracy: 0.6879\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "history_2 = model_2.fit(x_tr,y_tr,\n",
    "                    batch_size=128, epochs =50,\n",
    "                   validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = range(50)\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqq0lEQVR4nO3dd5wV1f3/8deHpRcFFojIUhNRBKStoGAUiDGIRIniTw0WbAghYouiMbEbU/iqwQKCoigEYqISVNQoiigEFRAUBJUoKIK0SJO++/n9ce4uy3Lv9rtt3s/HYx5750y55+zCfOaUOWPujoiIRFeVss6AiIiULQUCEZGIUyAQEYk4BQIRkYhTIBARibiqZZ2BwmrUqJG3atWqrLMhIlKhLFy4cJO7N463rcIFglatWrFgwYKyzoaISIViZqsTbVPTkIhIxCkQiIhEnAKBiEjEVbg+AhEpHfv27WPNmjXs3r27rLMihVCzZk3S0tKoVq1agY9RIBCRuNasWUO9evVo1aoVZlbW2ZECcHc2b97MmjVraN26dYGPi0TT0JQp0KoVVKkSfk6ZUtY5Ein/du/eTWpqqoJABWJmpKamFroWV+lrBFOmwNChsHNnWF+9OqwDDB5cdvkSqQgUBCqeovzNKn2N4NZbDwSBLDt3hnQREYlAIPjqq8Kli0j5sHnzZjp37kznzp054ogjaNasWfb63r178zx2wYIFjBw5Mt/v6NmzZ4nkdfbs2QwYMKBEzlUWKn0gaNGicOkiUjQl3ReXmprK4sWLWbx4McOGDeO6667LXq9evTr79+9PeGx6ejpjxozJ9zvmzZtXvExWEpU+ENx7L9SufXBa7dohXURKRlZf3OrV4H6gL66kB2YMGTKE66+/nj59+jBq1Cjef/99evbsSZcuXejZsyeffvopcPAd+h133MFll11G7969adOmzUEBom7dutn79+7dm0GDBnHMMccwePBgst7eOHPmTI455hhOOukkRo4cWag7/6lTp9KxY0c6dOjAqFGjAMjIyGDIkCF06NCBjh078sADDwAwZswYjj32WI477jjOP//84v+yCqHSdxZndQjfemtoDmrRIgQBdRSLlJy8+uJK+v/aZ599xhtvvEFKSgrbtm1jzpw5VK1alTfeeIPf/va3PPfcc4ccs2LFCt566y22b9/O0UcfzfDhww8ZZ//hhx+ybNkyjjzySHr16sXcuXNJT0/nqquuYs6cObRu3ZoLLrigwPlcu3Yto0aNYuHChTRo0IDTTjuN6dOn07x5c7755huWLl0KwJYtWwD44x//yJdffkmNGjWy00pLpa8RQPiHuGoVZGaGnwoCIiWrNPvizj33XFJSUgDYunUr5557Lh06dOC6665j2bJlcY8544wzqFGjBo0aNaJJkyasX7/+kH26d+9OWloaVapUoXPnzqxatYoVK1bQpk2b7DH5hQkEH3zwAb1796Zx48ZUrVqVwYMHM2fOHNq0acMXX3zB1Vdfzauvvsphhx0GwHHHHcfgwYOZPHkyVauW7j16JAKBiCRXafbF1alTJ/vz73//e/r06cPSpUt58cUXE46fr1GjRvbnlJSUuP0L8fbJah4qikTHNmjQgCVLltC7d28eeeQRrrjiCgBefvllRowYwcKFC+nWrVuefSAlTYFARIqtrPritm7dSrNmzQB46qmnSvz8xxxzDF988QWrVq0C4O9//3uBj+3Rowdvv/02mzZtIiMjg6lTp3LKKaewadMmMjMzOeecc7j77rtZtGgRmZmZfP311/Tp04c///nPbNmyhR07dpR4eRKp9H0EIpJ8ZdUXd9NNN3HJJZdw//3307dv3xI/f61atXj00Ufp168fjRo1onv37gn3nTVrFmlpadnr//jHP7jvvvvo06cP7k7//v0566yzWLJkCZdeeimZmZkA3HfffWRkZHDhhReydetW3J3rrruO+vXrl3h5ErHiVH3KQnp6uuvFNCLJt3z5ctq1a1fW2ShzO3bsoG7durg7I0aM4KijjuK6664r62zlKd7fzswWunt6vP3VNCQikocJEybQuXNn2rdvz9atW7nqqqvKOkslLulNQ2aWAiwAvnH3Abm2GfBXoD+wExji7ouSnScRkYK67rrryn0NoLhKo0ZwDbA8wbbTgaNiy1BgbCnkR0REckhqIDCzNOAM4PEEu5wFPO3BfKC+mTVNZp5ERORgya4RPAjcBGQm2N4M+DrH+ppY2kHMbKiZLTCzBRs3bizxTIqIRFnSAoGZDQA2uPvCvHaLk3bIMCZ3H+/u6e6e3rhx4xLLo4iIJLdG0As408xWAdOAvmY2Odc+a4DmOdbTgLVJzJOIVBC9e/fmtddeOyjtwQcf5Fe/+lWex2QNL+/fv3/cOXvuuOMORo8ened3T58+nU8++SR7/bbbbuONN94oRO7jK6/TVSctELj7Le6e5u6tgPOBN939wly7zQAutuAEYKu7r0tWnkSk4rjggguYNm3aQWnTpk0r8Hw/M2fOLPJDWbkDwV133cWpp55apHNVBKX+HIGZDTOzYbHVmcAXwEpgApA41ItIpAwaNIiXXnqJPXv2ALBq1SrWrl3LSSedxPDhw0lPT6d9+/bcfvvtcY9v1aoVmzZtAuDee+/l6KOP5tRTT82eqhrCMwLHH388nTp14pxzzmHnzp3MmzePGTNmcOONN9K5c2f++9//MmTIEP75z38C4QniLl260LFjRy677LLs/LVq1Yrbb7+drl270rFjR1asWFHgspb1dNWlMsWEu88GZsc+j8uR7sCI0siDiBTDtdfC4sUle87OneHBBxNuTk1NpXv37rz66qucddZZTJs2jfPOOw8z495776Vhw4ZkZGTwk5/8hI8++ojjjjsu7nkWLlzItGnT+PDDD9m/fz9du3alW7duAJx99tlceeWVAPzud7/jiSee4Oqrr+bMM89kwIABDBo06KBz7d69myFDhjBr1izatm3LxRdfzNixY7n22msBaNSoEYsWLeLRRx9l9OjRPP54ogGTB5SH6ar1ZLGIlFs5m4dyNgs9++yzdO3alS5durBs2bKDmnFye+edd/jFL35B7dq1OeywwzjzzDOzty1dupQf//jHdOzYkSlTpiScxjrLp59+SuvWrWnbti0Al1xyCXPmzMnefvbZZwPQrVu37Inq8lMepqvWpHMikr887tyTaeDAgVx//fUsWrSIXbt20bVrV7788ktGjx7NBx98QIMGDRgyZEjC6aezhEkMDjVkyBCmT59Op06deOqpp5g9e3ae58lvbrasqawTTXVdmHNmTVf92muv8cgjj/Dss88yceJEXn75ZebMmcOMGTO4++67WbZsWbEDgmoEIlJu1a1bl969e3PZZZdl1wa2bdtGnTp1OPzww1m/fj2vvPJKnuc4+eSTeeGFF9i1axfbt2/nxRdfzN62fft2mjZtyr59+5iS472a9erVY/v27Yec65hjjmHVqlWsXLkSgGeeeYZTTjmlWGUsD9NVq0YgIuXaBRdcwNlnn53dRNSpUye6dOlC+/btadOmDb169crz+K5du3LeeefRuXNnWrZsyY9//OPsbXfffTc9evSgZcuWdOzYMfvif/7553PllVcyZsyY7E5igJo1a/Lkk09y7rnnsn//fo4//niGDRt2yHfmpTxOV61pqEUkLk1DXXFpGmoRESkUBQIRkYhTIBCRhCpa07EU7W+mQCAicdWsWZPNmzcrGFQg7s7mzZupWbNmoY7TqCERiSstLY01a9agqd8rlpo1ax40KqkgFAhEJK5q1arRunXrss6GlAI1DYmIRJwCgYhIxCkQiIhEnAKBiEjEKRCIiEScAoGISMQpEIiIRJwCgYhIxCkQiIhEXNICgZnVNLP3zWyJmS0zszvj7NPbzLaa2eLYcluy8iMiIvElc4qJPUBfd99hZtWAd83sFXefn2u/d9x9QBLzISIieUhaIPAwZWHWyzSrxRZNYygiUs4ktY/AzFLMbDGwAXjd3d+Ls9uJseajV8ysfYLzDDWzBWa2QDMhioiUrKQGAnfPcPfOQBrQ3cw65NplEdDS3TsBDwHTE5xnvLunu3t648aNk5llEZHIKZVRQ+6+BZgN9MuVvs3dd8Q+zwSqmVmj0siTiIgEyRw11NjM6sc+1wJOBVbk2ucIM7PY5+6x/GxOVp5ERORQyRw11BSYZGYphAv8s+7+kpkNA3D3ccAgYLiZ7Qd2Aee73osnIlKqkjlq6COgS5z0cTk+Pww8nKw8iIhI/vRksYhIxCkQiIhEnAKBiEjEKRCIiEScAoGISMQpEIiIRJwCgYhIxCkQiIhEnAKBiEjEKRCIiEScAoGISMQpEIiIRJwCgYhIxCkQiIhEnAKBiEjEKRCIiEScAoGISMQpEIiIRJwCgYhIxCUtEJhZTTN738yWmNkyM7szzj5mZmPMbKWZfWRmXZOVHxERiS9pL68H9gB93X2HmVUD3jWzV9x9fo59TgeOii09gLGxnyIiUkqSViPwYEdstVps8Vy7nQU8Hdt3PlDfzJomK08iInKopPYRmFmKmS0GNgCvu/t7uXZpBnydY31NLE1EREpJUgOBu2e4e2cgDehuZh1y7WLxDsudYGZDzWyBmS3YuHFjEnIqIhJdpTJqyN23ALOBfrk2rQGa51hPA9bGOX68u6e7e3rjxo2TlU0RkUhK5qihxmZWP/a5FnAqsCLXbjOAi2Ojh04Atrr7umTlSUREDpXMUUNNgUlmlkIIOM+6+0tmNgzA3ccBM4H+wEpgJ3BpEvMjIiJxJC0QuPtHQJc46eNyfHZgRLLyICIi+dOTxSIiEadAICIScQoEIiIRp0AgIhJxCgQiIhGnQCAiEnEKBCIiEadAICIScQoEIiIRp0AgIhJxCgQiIhGnQCAiEnEKBCIiEadAICIScQoEIiIRV6BAYGZ1zKxK7HNbMzvTzKolN2siIlIaClojmAPUNLNmwCzCm8SeSlamRESk9BQ0EJi77wTOBh5y918AxyYvWyIiUloKHAjM7ERgMPByLC2Z7zsWEZFSUtBAcC1wC/CCuy8zszbAW0nLlYiIlJoC3dW7+9vA2wCxTuNN7j4yr2PMrDnwNHAEkAmMd/e/5tqnN/Av4MtY0vPuflch8i8iIsVU0FFDfzOzw8ysDvAJ8KmZ3ZjPYfuBG9y9HXACMMLM4vUrvOPunWOLgoCISCkraNPQse6+DRgIzARaABfldYC7r3P3RbHP24HlQLOiZ1VERJKhoIGgWuy5gYHAv9x9H+AF/RIzawV0Ad6Ls/lEM1tiZq+YWfsExw81swVmtmDjxo0F/VoRESmAggaCx4BVQB1gjpm1BLYV5EAzqws8B1wbq1XktAho6e6dgIeA6fHO4e7j3T3d3dMbN25cwCyLiEhBFCgQuPsYd2/m7v09WA30ye+4WC3iOWCKuz8f57zb3H1H7PNMQs2jUeGKICIixVHQzuLDzez+rOYZM/s/Qu0gr2MMeAJY7u73J9jniNh+mFn3WH42F6oEIiJSLAV9KGwisBT4f7H1i4AnCU8aJ9Irtt/HZrY4lvZbQkcz7j4OGAQMN7P9wC7gfHcvcN+DiIgUX0EDwQ/d/Zwc63fmuLjH5e7vApbPPg8DDxcwDyIikgQF7SzeZWYnZa2YWS/CHbyIiFRwBa0RDAOeNrPDY+vfAZckJ0siIlKaCjrFxBKgk5kdFlvfZmbXAh8lMW8iIlIKCvWGsthwz6xnAa5PQn5ERKSUFedVlXl2BIuISMVQnECgYZ4iIpVAnn0EZrad+Bd8A2olJUciIlKq8qwRuHs9dz8szlLP3SvFG8qmTIFWraBKlfBzypSyzpGISOmqFBfzopoyBYYOhZ07w/rq1WEdYPDgssuXiEhpKk4fQcXy7bdwzTWwd2920q23HggCWXbuDOkiIlERnUAwdy6MGQMjD7xh86uv4u+aKF1EpDKKTiA45xy4+WZ47DEYOxaAFi3i75ooXUSkMopOIAC45x4444xQK3j7be69F2rXPniX2rXh3nvViSwi0RGtQJCSEq7oP/whDBrE4JNWM348tGwJZuHn+PFh16FDQ+ex+4FOZAUDEamMrKJN/5+enu4LFiwo3kk++wy6dw+3+nPnQp2D37HTqlW4+OfWsiWsWlW8rxYRKQtmttDd0+Nti1aNIEvbtjBtGnz8MVx6abjtz0GdyCISJdEMBAD9+sEf/wj/+Af84Q8HbVInsohESXQDAcBvfhOeHPvd78LQ0ljNIK9OZBGRyibagcAMJkyAAQPCw2YDB8LmzQweTNxOZD1tLCKVUbQDAUCtWjBjBjzwALzyCnTqBG+/zeDBoWM4MzP8zAoCGlYqIpVN0gKBmTU3s7fMbLmZLTOza+LsY2Y2xsxWmtlHZtY1WfnJkxlcey3Mnx/agPr2hTvugP37D9ota24iDSsVkcokmTWC/cAN7t4OOAEYYWbH5trndOCo2DIUGJvE/OSva1dYuBAuvBDuvDMEhG++yd6suYlEpDJKWiBw93Xuvij2eTuwHGiWa7ezgKc9mA/UN7OmycpTgdSrB5MmwTPPwKJF8MtfZncia1ipiFRGpdJHYGatgC7Ae7k2NQO+zrG+hkODBWY21MwWmNmCjRs3Ji2fB7nwQvjLX2DOHPjXvwANKxWRyinpgcDM6gLPAdfmePF99uY4hxzyqLO7j3f3dHdPb9y4cTKyGd+VV0K7dnDjjbB3r4aVikillNRAYGbVCEFgirs/H2eXNUDzHOtpwNpk5qlQqlaF0aNh5UoYO1bDSkWkUkrmqCEDngCWu/v9CXabAVwcGz10ArDV3dclK09Fcvrp8NOfhs7j//1Pw0pFpNJJZo2gF3AR0NfMFseW/mY2zMyGxfaZCXwBrAQmAL9KYn6Kxgz+7/9g69YwjXUcGlYqIhVZNGcfLYorrwyjiZYtg6OOOmiTZisVkfJOs4+WhLvvhurVYdSoQzZpWKmIVGQKBAV1xBHhVZcvvBCGlOagYaUiUpEpEBTG9ddDWlr4mZmZnaxXXopIRaZAUBi1a8N994VpKP72t+zkRMNKQZ3IIlL+qbO4sDIzoUePcFVftCjUEBJQJ7KIlBfqLC5JVarA00/Drl0waBDs2ZNwV3Uii0hFoEBQFO3awZNPwnvvhemrE1AnsohUBAoERTVoUJiDaNw4eOqpuLvkNzeROpJFpDxQICiOP/wB+vSBYcNCf0Euec1NpKeRRaS8UGdxcW3YAN26hQnqFiyA1NQCHaaOZBEpTeosTqYmTeC552Dt2nCrn5FRoMPUkSwi5YUCQUno3h0eegheew1uv71Ah+TVkay+AxEpTQoEJeXKK+Hyy0NP8G23Zb/eMpFEHcn9+6vvQERKlwJBSTGDsWPhssvCBHVXXAH79iXcPVFH8syZsHPnwfvu3Am33prk/ItIZCkQlKRq1eDxx+H3v4eJE2HgQPj++4S7x3vJTV59B2oyEpFkUCAoaWZw113w2GPw6qtheOmGDQU+PFHfQcOGajISkeRQIEiWoUPDlNVLl0LPnuG9xwWQqO8A1GQkIsmhQJBMZ54Jb74JW7bAiSeGToC9e/M8JFHfwf/+F39/NRmJSHHpgbLS8NlncPHFYW6iFi3gllvg0kuhRo0CnyLRA2ipqWH+u5y1hdq1DzzBLCICeqCs7LVtC//5T+gzaNYMhg+HH/0IHnkEdu8u0CnUZCQiyZK0QGBmE81sg5ktTbC9t5ltNbPFseW2ZOWlXDCDn/0M5s6F118Pt/i//nUICM89l+/hRWkyAjUbiUj+klkjeArol88+77h759hyVxLzUn6Ywamnhvcez5oV3oU8aFCoJezaleeh8Yab5veEskYaiUh+khYI3H0OkOB+VTCDvn1h3rwD01n36AHLlxfqNHlNdX3rrWo2EpH8lXUfwYlmtsTMXjGz9ol2MrOhZrbAzBZs3LixNPOXfNWrw5//DK+8At9+C+np4WG0Anbi5zXVtR5OE5GCSOqoITNrBbzk7h3ibDsMyHT3HWbWH/irux+V3zkr5Kihglq7Fi66KAw5/eUv4Y47wrCgww+HlJRCn04jjUQkS7kcNeTu29x9R+zzTKCamTUqq/yUC0ceCf/+N9xzD0ybFkYbpaaGdx3Urx+u7F26wIABYWK7f/0L1qxJWHsoykgj1RREoqdqWX2xmR0BrHd3N7PuhKC0uazyU26kpIQr8plnhreefffdgWXLlvDziy9CU1JmZjimSZPwcpyTToKRI6FuXeDA3f2tt4bmoBYtQnC46KL4X53VmZwVJLLWc55LRCqfpDUNmdlUoDfQCFgP3A5UA3D3cWb2a2A4sB/YBVzv7vPyO2+lbhoqjO+/hyVLYOHCsCxaBB9/DGlp8PDDcNZZCQ9N1GSUkhL/vTotWx7ofM4ZUBQcRCqOvJqG9GRxZTJvHlx1VZjfaOBAGDMGmjc/ZLesYaW5+whyNxfllHu7+hREKpZy2UcgSdCzZ6gZ/OlP4W1pxx4LDz4I+/cftFuikUYtW8Y/bUqK+hREKjPVCCqrL7+EESNCX0KXLnD99aGWEOs/iEc1BZHKSzWCKGrdGl5+GZ59NnQwX3QR/OAH4Qo9c2bct6eVZE0BVFsQqShUI4iCzMzQfzB58oHA0LgxnHceXH11GKaah8LWFMzgmWfiH6PagkjZUI0g6qpUCUNLx40LTy9Pnw69e8OECaEfYcQIWL8+4eGFrSm0aJH39BaqKYiUL6oRRNmGDXDnneG1mrVqwU03hb6EOnUKdHiimsL48aElKtE/LfUriJQ+1QgkviZNwjsRli2D004LTysfdVSoKeQaaRRPXvMcJZoVVSOQRMof1QjkgKyZUOfNC30IP/kJ/PSnYdrsRFd2CK/f/P57aNAgO0kjkETKF9UIpGB69oR33w1zGP3sZzB7Nlx+ebjVP/ro8CKdMWNg1Cg4//ywf1oa1KwJDRuGl+xceilMnMjgHisZ/5jrWQWRCkA1AknMPTQbvf56WN5+O1ydq1cPNYSspWXLcPs+f3544c7m2JRRRxwBJ58cOqb79oW2bZnyNyuxmgLAPbd8T7Ov5/PfFn245w9VVHsQSSCvGgHuXqGWbt26uZSR3bvdv/3WPSMj8T6Zme7LlrmPG+f+y1+6N2vmHkKKe9Om7oMH+7wrn/BeR37hZu4tW7pPnhx+Zu2Wc0lJiZ/epOE+/1X18f4NTd3Bx3OF16mV4ZMnh2xknTPnd0TCxo3up53m/tRTZZ0TKWeABZ7gulrmF/bCLgoEFUxmpvvnn7s/9pj7eee5N2ly4Greq5f7a6+5Z2b65MnutWsffLHPvR6WTB/ADF9GO3fwd+npjzDcHXwSF3mbFvsSnis7GHz8sfuGDWX6a0mKHTvcu3cPBa5e3f3DD8s6R1KOKBBI+ZGZ6b50qfvo0e5paeGfYI8e7i+/7JOfyTzkLj5nTeF43vO3OMUdfAVtfSDPO2Q6uN/K3e7gUznPf9hib9xaRPvmW/3TU3/lDr6WI/ysI+ZXnprC3r3u/fq5V6ni/vjj7kce6d62rfv27WWdM8lp61b3hQvd//5396lT3ffvL7WvViCQ8mn37lBTyLrap6e7z5gR/rO89577pEm+9Oc3+4yUs3w5R7uDf0sTH1ntUf9Bw0Mv9jfwF3fw5xno1dl90LYzeNG/Is0zMH+UYb6SNr6LGn5F9Uk+eXIFb0rKyHC/8MJQ0AkTQtrs2SEoXHxx2eZt5073J58Mwf6009z/97+yzU9pmzvXfciQUPvNWRvOWi64IATxUqBAIOXb3r3uTzzh3qbNof9Rqlb1LUe285m1z/ab+JMf23xb9oU7XvPP+xePcQd/if5eg13ehG99Kue5g39EB+/OfAf3hmzyWfRxB3+o5m+8bq39cZuSSixAZGa6v/uu+/Dh7g88kHc/S2HPe/31IdP33HPwtttvD+mTJpXMdxXGypXuN9zg3qBByMPRR7tXq+bevr3711/nf/yXX4byrFuX9Kwmzdtvu9eq5d6wofspp7hfcYX7H//o/txz7kuWuN93X+wu5YwQMJNMgUAqhn37wpX2vvvcX3jBfcWKPO+WEl2k51/2mGdgPp/uvpkGvpvqfke1u70aew6OMez1hxjhDv4yp/thbDloe2qqe+1amd6Y9d6CVUULEN9+6/7nP4cLYVbbPbifemr+F7nMTPfnn3e/7LLQ+f755yEtpz/9KZzv6qsP3bZ/f7gA1akTfpfJlJER8jd1amiiyurpP/dc97feCnmbNcu9Xr3QJLh0afzzZGaGstatG87RsKH7M88cWrbi2rUr1FRuvtn9m29K9tzu7vPnhzIcc4z7+vWJ9xs3LvwjOvnkUBNOIgUCiZy5Q5/y/VTxd+jlfY/8JM+RSUMZ53up6ss52gfxrF/PaJ/A5f4uPX0TDbN3fJPe/gue8yYN9+XZGT31ie/9isbT/XkG+l6qenbH+MSJoc1+woRwp9ikifu//x2/AIsWhYt47l7zFi1CYJgyxf3hh0Pa+ecnrmGsWRMiWqdO4eJXHJmZ7t99Fy74774bLmLDh7v37Hngwp01Ouz22+NfYD/80P2II9zr13d/552Dt331lftPfxrO0bev+xtvuJ94YlgfMCCUpbhWrw4X/9TUA/mtVy/U0vbty/vYxYvdf/ObcEefV2D68MNQvh/+sGBBZupU96pV3bt1C6O+4tm4MfwDe//9/M+XgAKBRFOuoa6JmpNSU91PZrZv5MDFYT2NfTYn+1iu8mt4wG/mD/4lLd3BV9PcR3Gfp7IxeyTT0Sz3uxrc72s7/NR3UcOz+jP+xI3euebyQ2oRpzZd6t81Ozas3HLLgYvQunXul18e0hs1ch87Nmz79FP3Rx91P/vsA80tWTWLPXvy/j289FLY99e/Ltjvbd0693/+0/3aa0MwOvbYELTijeU97DD3H/84nHvChHChyq/N+8svQw2pRo1Q48nMDE2Dhx0Wai+PPnrg77Z/v/v994fAefjhIZgWtnaQmen+5pvuv/hF6DepUsV94MBQQ/n8c/fTTw9lOe64EOByHztzZvg95yz3KaeEYJ3bsmXh79a8ufuqVQXP48svu9es6d6uXWg627/f/T//cb/ttjASzMyza35FlFcg0ANlEilTphz67mUI02HU3rmRH7GSz2jL7tqp1Kp14Nk4gCpk8HNe5Goe4ie8yW5q8G9OoyMf05pVAHxerR0z9p3Oq/RjNr3ZH17TTWoq7Np18INxqbV2Mr/HNfxo9uMsqNGTGXv6caP9hTpVdlHlmpHw+99D/fqHFiIjAz78MCwXXJDny4ay3XAD3H8//Pa34Wnw6tUPLDVqwMaNMHdueLL8v/8Nx9SqFV5q1LQpNGoUCpGaGj43agTt2oVHvc0K/Xdg0yYYMAA++ACOPx7eew9OOQUmToQ2bQ7df+XK8JT7nDlhXqyf/QyqVQv5z/lzyxZYswa+/jr8zFq+/z48/X7llTB8+MGPuLuHGXmvuSYcd+mlYTLG116DBx6ATz6BI4+EkSNDHv75z/C32bw5rN9zT3jXx+efhwcozUI+f/Sjwv1O5swJv5PatcNcX5s3h8fpe/SAfv3g9NOhW7eQVgR6oEwkH/Ha/POqQRzLUn+UYb6a5j6dM/0qxnqvZl9m37gVdElNdb+k+t98K/Xcwadzph9X89OSH8m0Z09oh84rM40bh7vm0aNDG3d+NY3i2rEjNPnUquX+17/m34GekRGaw+rVy7scVaqEfogTTnAfNCjUbCZNyr9DdscO91GjQjNN1rk6dw59FLl/F999Fzrpq1YN+bnjjlALaNQo1AqKauHC8He6+OLQZLRpU9HPlQtl0TQETAQ2AEsTbDdgDLAS+AjoWpDzKhBIaSpMgMirHyK/pQWr/ATmHdxRnUc/RJGCREZGGL757behPX7lSvdPPglt3/E6oktDZma4ABfGvn3u27aFi+TataHd//PPwwV4zZr82/rz88knoR/hzTfz/518+qn7z38e/kD168dvLionyioQnAx0zSMQ9AdeiQWEE4D3CnJeBQIpDxJdiPOqRRQlQOResr4rUZCo0M9DVGTvvOO+fHlZ5yJPeQWCpPYRmFkr4CV37xBn22PAbHefGlv/FOjt7uvyOqf6CKS8y6sfIvfkebn7IfJjFs65evWh2+L1Q+ScoC93njRBX7SU12momwFf51hfE0s7hJkNNbMFZrZg48aNpZI5kaIaPBhWrQqvil61KqwneonPX/8aLtY51a4dLurxtGgRLubxbN4cfyrva64JQWj16lB/WL06rE+ZkniKb039HTGJqgolsQCtSNw09DJwUo71WUC3/M6ppiGpbEqrHyJeR3W87xg+vGj9E2qWKt/Io2moahnFHwg1gOY51tOAtWWUF5Eyk1VjiCdRc05JNDPF23fnzlBTycg4NP3WWw/97qzaxdy5MGnSoelZ5ZPyrSybhmYAF1twArDV8+kfEImSeE1MWekl0cyUSO4gkOWrr0IwiNf8NH584d8wp+anciRRVaG4CzAVWAfsI9z9Xw4MA4bFthvwCPBf4GMgvSDnVdOQSGKFfR4iXpNRopcBZZ23sE1QhW1+yquJSc1SRYemmBCJtsIEiLwu0oV9k1xh0/N6fqIo+VWAOECBQETiKuwddmEvxiXRqZ1VGylsEMovqEQtQCgQiEiJKUzwKOzFO9FiVrRmqcIGiMKWL6/08kaBQETKRGFrEIn6LYpSIyhKraOw+S3pZqlkBhUFAhEpM4W5k85v+oySCCp51TpKqg+kKM1SyZ46RIFARCqMkho1VNjRUkUdFVVSzVKJglB+TVkFlVcg0PsIRKTSKsy8T+PHh33jzeOUkhL/+YpE6YXVsmXIY2Euxy1bhudLCqq8zjUkIpJUhZn3afDgECjiPZQ3dGjh0gv7EF9WoCrsMSVFgUBEIqewT20/+mjh0osymWCiIJTXMSVFTUMiIklQ2GapwYOLdkxB5dU0VJaTzomIVFpFmUywKMeUBNUIREQiQJ3FIiKSkAKBiEjEKRCIiEScAoGISMQpEIiIRFyFGzVkZhuBOA+BF0gjYFMJZqciiWrZVe5oUbkTa+nujeNtqHCBoDjMbEGi4VOVXVTLrnJHi8pdNGoaEhGJOAUCEZGIi1ogGF/WGShDUS27yh0tKncRRKqPQEREDhW1GoGIiOSiQCAiEnGRCQRm1s/MPjWzlWZ2c1nnJ1nMbKKZbTCzpTnSGprZ62b2eexng7LMYzKYWXMze8vMlpvZMjO7JpZeqctuZjXN7H0zWxIr952x9Epd7ixmlmJmH5rZS7H1Sl9uM1tlZh+b2WIzWxBLK1a5IxEIzCwFeAQ4HTgWuMDMji3bXCXNU0C/XGk3A7Pc/ShgVmy9stkP3ODu7YATgBGxv3FlL/seoK+7dwI6A/3M7AQqf7mzXAMsz7EelXL3cffOOZ4dKFa5IxEIgO7ASnf/wt33AtOAs8o4T0nh7nOA/+VKPguYFPs8CRhYmnkqDe6+zt0XxT5vJ1wcmlHJy+7BjthqtdjiVPJyA5hZGnAG8HiO5Epf7gSKVe6oBIJmwNc51tfE0qLiB+6+DsIFE2hSxvlJKjNrBXQB3iMCZY81jywGNgCvu3skyg08CNwEZOZIi0K5Hfi3mS00s6GxtGKVOyqvqrQ4aRo3WwmZWV3gOeBad99mFu9PX7m4ewbQ2czqAy+YWYcyzlLSmdkAYIO7LzSz3mWcndLWy93XmlkT4HUzW1HcE0alRrAGaJ5jPQ1YW0Z5KQvrzawpQOznhjLOT1KYWTVCEJji7s/HkiNRdgB33wLMJvQRVfZy9wLONLNVhKbevmY2mcpfbtx9beznBuAFQtN3scodlUDwAXCUmbU2s+rA+cCMMs5TaZoBXBL7fAnwrzLMS1JYuPV/Alju7vfn2FSpy25mjWM1AcysFnAqsIJKXm53v8Xd09y9FeH/85vufiGVvNxmVsfM6mV9Bk4DllLMckfmyWIz609oU0wBJrr7vWWbo+Qws6lAb8K0tOuB24HpwLNAC+Ar4Fx3z92hXKGZ2UnAO8DHHGgz/i2hn6DSlt3MjiN0DqYQbuyedfe7zCyVSlzunGJNQ79x9wGVvdxm1oZQC4DQtP83d7+3uOWOTCAQEZH4otI0JCIiCSgQiIhEnAKBiEjEKRCIiEScAoGISMQpEIjEmFlGbEbHrKXEJiwzs1Y5Z4QVKU+iMsWESEHscvfOZZ0JkdKmGoFIPmLzv/8pNu//+2b2o1h6SzObZWYfxX62iKX/wMxeiL0jYImZ9YydKsXMJsTeG/Dv2JPAmNlIM/skdp5pZVRMiTAFApEDauVqGjovx7Zt7t4deJjwhDqxz0+7+3HAFGBMLH0M8HbsHQFdgWWx9KOAR9y9PbAFOCeWfjPQJXaeYckpmkhierJYJMbMdrh73Tjpqwgvf/kiNrHdt+6eamabgKbuvi+Wvs7dG5nZRiDN3ffkOEcrwhTRR8XWRwHV3P0eM3sV2EGYCmR6jvcLiJQK1QhECsYTfE60Tzx7cnzO4EAf3RmEN+h1AxaamfrupFQpEIgUzHk5fv4n9nkeYeZLgMHAu7HPs4DhkP3SmMMSndTMqgDN3f0twktW6gOH1EpEkkl3HiIH1Iq96SvLq+6eNYS0hpm9R7h5uiCWNhKYaGY3AhuBS2Pp1wDjzexywp3/cGBdgu9MASab2eGEFyg9EHuvgEipUR+BSD5ifQTp7r6prPMikgxqGhIRiTjVCEREIk41AhGRiFMgEBGJOAUCEZGIUyAQEYk4BQIRkYj7/1SPgKyxQeqvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = range(50)\n",
    "train_loss_2 = history_2.history['loss']\n",
    "val_loss_2 = history_2.history['val_loss']\n",
    "plt.plot(epochs,train_loss_2,'bo',label= 'Training Loss')\n",
    "plt.plot(epochs,val_loss_2,'r',label= 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model_3 = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32,3, activation='relu',input_shape=[32,32,3]),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Conv2D(64,4,activation='relu'),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               590080    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 626,378\n",
      "Trainable params: 626,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               590080    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 626,378\n",
      "Trainable params: 626,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               590080    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 626,378\n",
      "Trainable params: 626,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizers.rmsprop_v2.RMSprop(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.7737 - accuracy: 0.7318 - val_loss: 1.0717 - val_accuracy: 0.6711\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.7749 - accuracy: 0.7295 - val_loss: 1.0606 - val_accuracy: 0.6684\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.7664 - accuracy: 0.7340 - val_loss: 1.1595 - val_accuracy: 0.6674\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 0.7588 - accuracy: 0.7347 - val_loss: 1.0607 - val_accuracy: 0.6762\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.7542 - accuracy: 0.7369 - val_loss: 1.1451 - val_accuracy: 0.6661\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.7484 - accuracy: 0.7413 - val_loss: 1.0812 - val_accuracy: 0.6662\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 23s 72ms/step - loss: 0.7492 - accuracy: 0.7393 - val_loss: 1.2242 - val_accuracy: 0.6713\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 0.7358 - accuracy: 0.7462 - val_loss: 1.1230 - val_accuracy: 0.6484\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7322 - accuracy: 0.7444 - val_loss: 1.1005 - val_accuracy: 0.6774\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.7269 - accuracy: 0.7490 - val_loss: 1.1535 - val_accuracy: 0.6774\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.7192 - accuracy: 0.7511 - val_loss: 1.1135 - val_accuracy: 0.6698\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.7137 - accuracy: 0.7514 - val_loss: 1.2073 - val_accuracy: 0.6743\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.7148 - accuracy: 0.7521 - val_loss: 1.0788 - val_accuracy: 0.6765\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7047 - accuracy: 0.7547 - val_loss: 1.1347 - val_accuracy: 0.6711\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 0.7045 - accuracy: 0.7556 - val_loss: 1.2456 - val_accuracy: 0.6181\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.6975 - accuracy: 0.7574 - val_loss: 1.1591 - val_accuracy: 0.6766\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.7106 - accuracy: 0.7549 - val_loss: 1.0336 - val_accuracy: 0.6690\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.6901 - accuracy: 0.7590 - val_loss: 1.0608 - val_accuracy: 0.6752\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6867 - accuracy: 0.7622 - val_loss: 1.1209 - val_accuracy: 0.6472\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6862 - accuracy: 0.7627 - val_loss: 1.0790 - val_accuracy: 0.6718\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.6781 - accuracy: 0.7635 - val_loss: 1.1038 - val_accuracy: 0.6324\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6760 - accuracy: 0.7663 - val_loss: 1.3577 - val_accuracy: 0.6680\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.6810 - accuracy: 0.7670 - val_loss: 1.0936 - val_accuracy: 0.6772\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6730 - accuracy: 0.7707 - val_loss: 1.2961 - val_accuracy: 0.6752\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6676 - accuracy: 0.7720 - val_loss: 1.0884 - val_accuracy: 0.6719\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6632 - accuracy: 0.7686 - val_loss: 1.1871 - val_accuracy: 0.6762\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6614 - accuracy: 0.7704 - val_loss: 1.1780 - val_accuracy: 0.6604\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6543 - accuracy: 0.7742 - val_loss: 1.2380 - val_accuracy: 0.6860\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6568 - accuracy: 0.7719 - val_loss: 1.2531 - val_accuracy: 0.6743\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6593 - accuracy: 0.7736 - val_loss: 1.1510 - val_accuracy: 0.6754\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6510 - accuracy: 0.7757 - val_loss: 1.2670 - val_accuracy: 0.6667\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.6500 - accuracy: 0.7761 - val_loss: 1.4574 - val_accuracy: 0.6769\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6456 - accuracy: 0.7782 - val_loss: 1.1315 - val_accuracy: 0.6515\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6487 - accuracy: 0.7763 - val_loss: 1.1043 - val_accuracy: 0.6602\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6462 - accuracy: 0.7801 - val_loss: 1.2268 - val_accuracy: 0.6760\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6515 - accuracy: 0.7782 - val_loss: 1.3189 - val_accuracy: 0.6579\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.6360 - accuracy: 0.7820 - val_loss: 1.1784 - val_accuracy: 0.6451\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6400 - accuracy: 0.7824 - val_loss: 1.3850 - val_accuracy: 0.6809\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.6362 - accuracy: 0.7804 - val_loss: 1.1407 - val_accuracy: 0.6730\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6406 - accuracy: 0.7811 - val_loss: 1.2919 - val_accuracy: 0.6705\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6377 - accuracy: 0.7817 - val_loss: 1.1629 - val_accuracy: 0.6633\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6378 - accuracy: 0.7831 - val_loss: 1.3778 - val_accuracy: 0.6858\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6344 - accuracy: 0.7844 - val_loss: 1.2676 - val_accuracy: 0.6915\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6228 - accuracy: 0.7868 - val_loss: 1.1865 - val_accuracy: 0.6677\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6293 - accuracy: 0.7871 - val_loss: 1.6247 - val_accuracy: 0.6669\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6308 - accuracy: 0.7845 - val_loss: 1.3875 - val_accuracy: 0.6733\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6234 - accuracy: 0.7888 - val_loss: 1.2653 - val_accuracy: 0.6666\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.6221 - accuracy: 0.7858 - val_loss: 1.3053 - val_accuracy: 0.6859\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.6165 - accuracy: 0.7889 - val_loss: 1.1999 - val_accuracy: 0.6644\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.6131 - accuracy: 0.7912 - val_loss: 1.3146 - val_accuracy: 0.6767\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "history_3 = model_2.fit(x_tr,y_tr,\n",
    "                    batch_size=128, epochs =50,\n",
    "                   validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = range(50)\n",
    "train_loss_3 = history_3.history['loss']\n",
    "val_loss_3 = history_3.history['val_loss']\n",
    "plt.plot(epochs,train_loss_3,'bo',label= 'Training Loss')\n",
    "plt.plot(epochs,val_loss_3,'r',label= 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
